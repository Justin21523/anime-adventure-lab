#!/usr/bin/env python3
# scripts/test_monitor.py
"""
æ¸¬è©¦ç›£æ§å’Œå ±å‘Šå·¥å…·
"""

import time
import json
import subprocess
import psutil
from pathlib import Path
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart


class TestMonitor:
    def __init__(self, config_file="test_monitor_config.json"):
        self.config = self.load_config(config_file)
        self.results_history = []

    def load_config(self, config_file):
        """è¼‰å…¥ç›£æ§é…ç½®"""
        default_config = {
            "monitoring": {
                "interval_minutes": 60,
                "max_history": 100,
                "alert_thresholds": {
                    "failure_rate": 0.1,
                    "response_time": 5.0,
                    "memory_growth": 100,  # MB
                },
            },
            "notifications": {
                "email": {
                    "enabled": False,
                    "smtp_server": "smtp.gmail.com",
                    "smtp_port": 587,
                    "username": "",
                    "password": "",
                    "recipients": [],
                },
                "slack": {"enabled": False, "webhook_url": ""},
            },
            "test_suites": [
                {
                    "name": "smoke",
                    "command": ["python", "tests/run_tests.py", "--smoke"],
                },
                {
                    "name": "unit",
                    "command": [
                        "python",
                        "-m",
                        "pytest",
                        "tests/test_core_modules.py",
                        "-q",
                    ],
                },
                {
                    "name": "integration",
                    "command": [
                        "python",
                        "-m",
                        "pytest",
                        "tests/test_api_endpoints.py",
                        "-q",
                    ],
                },
            ],
        }

        config_path = Path(config_file)
        if config_path.exists():
            with open(config_path, "r") as f:
                return json.load(f)
        else:
            # å‰µå»ºé»˜èªé…ç½®
            with open(config_path, "w") as f:
                json.dump(default_config, f, indent=2)
            return default_config

    def run_test_suite(self, test_config):
        """åŸ·è¡Œæ¸¬è©¦å¥—ä»¶"""
        start_time = time.time()

        try:
            result = subprocess.run(
                test_config["command"],
                capture_output=True,
                text=True,
                timeout=300,  # 5åˆ†é˜è¶…æ™‚
            )

            duration = time.time() - start_time

            return {
                "name": test_config["name"],
                "success": result.returncode == 0,
                "duration": duration,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "timestamp": datetime.now().isoformat(),
            }

        except subprocess.TimeoutExpired:
            return {
                "name": test_config["name"],
                "success": False,
                "duration": time.time() - start_time,
                "stdout": "",
                "stderr": "Test suite timed out",
                "timestamp": datetime.now().isoformat(),
            }
        except Exception as e:
            return {
                "name": test_config["name"],
                "success": False,
                "duration": time.time() - start_time,
                "stdout": "",
                "stderr": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def collect_system_metrics(self):
        """æ”¶é›†ç³»çµ±æŒ‡æ¨™"""
        return {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "memory_available": psutil.virtual_memory().available / 1024 / 1024,  # MB
            "disk_percent": psutil.disk_usage("/").percent,
            "timestamp": datetime.now().isoformat(),
        }

    def run_monitoring_cycle(self):
        """åŸ·è¡Œä¸€å€‹ç›£æ§é€±æœŸ"""
        cycle_start = datetime.now()
        print(f"ğŸ”„ é–‹å§‹ç›£æ§é€±æœŸ: {cycle_start}")

        # æ”¶é›†ç³»çµ±æŒ‡æ¨™
        system_metrics = self.collect_system_metrics()

        # åŸ·è¡Œæ¸¬è©¦å¥—ä»¶
        test_results = []
        for test_config in self.config["test_suites"]:
            print(f"   ğŸ§ª åŸ·è¡Œæ¸¬è©¦å¥—ä»¶: {test_config['name']}")
            result = self.run_test_suite(test_config)
            test_results.append(result)

            status = "âœ…" if result["success"] else "âŒ"
            print(f"      {status} {result['duration']:.1f}s")

        # å‰µå»ºç›£æ§çµæœ
        monitoring_result = {
            "cycle_start": cycle_start.isoformat(),
            "cycle_end": datetime.now().isoformat(),
            "system_metrics": system_metrics,
            "test_results": test_results,
            "summary": {
                "total_tests": len(test_results),
                "passed_tests": sum(1 for r in test_results if r["success"]),
                "failed_tests": sum(1 for r in test_results if not r["success"]),
                "average_duration": (
                    sum(r["duration"] for r in test_results) / len(test_results)
                    if test_results
                    else 0
                ),
            },
        }

        # ä¿å­˜åˆ°æ­·å²è¨˜éŒ„
        self.results_history.append(monitoring_result)

        # ä¿æŒæ­·å²è¨˜éŒ„å¤§å°é™åˆ¶
        max_history = self.config["monitoring"]["max_history"]
        if len(self.results_history) > max_history:
            self.results_history = self.results_history[-max_history:]

        # æª¢æŸ¥è­¦å ±æ¢ä»¶
        self.check_alerts(monitoring_result)

        # ä¿å­˜çµæœ
        self.save_results()

        return monitoring_result

    def check_alerts(self, result):
        """æª¢æŸ¥è­¦å ±æ¢ä»¶"""
        thresholds = self.config["monitoring"]["alert_thresholds"]
        alerts = []

        # æª¢æŸ¥å¤±æ•—ç‡
        if result["summary"]["total_tests"] > 0:
            failure_rate = (
                result["summary"]["failed_tests"] / result["summary"]["total_tests"]
            )
            if failure_rate > thresholds["failure_rate"]:
                alerts.append(f"æ¸¬è©¦å¤±æ•—ç‡éé«˜: {failure_rate:.1%}")

        # æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“
        avg_duration = result["summary"]["average_duration"]
        if avg_duration > thresholds["response_time"]:
            alerts.append(f"å¹³å‡éŸ¿æ‡‰æ™‚é–“éé•·: {avg_duration:.1f}s")

        # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
        memory_percent = result["system_metrics"]["memory_percent"]
        if memory_percent > 90:
            alerts.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {memory_percent:.1f}%")

        # ç™¼é€è­¦å ±
        if alerts:
            self.send_alerts(alerts, result)

    def send_alerts(self, alerts, result):
        """ç™¼é€è­¦å ±é€šçŸ¥"""
        alert_message = (
            f"""
ğŸš¨ Multi-Modal Lab æ¸¬è©¦è­¦å ±

æ™‚é–“: {result['cycle_start']}

è­¦å ±å…§å®¹:
"""
            + "\n".join(f"- {alert}" for alert in alerts)
            + f"""

ç³»çµ±ç‹€æ…‹:
- CPUä½¿ç”¨ç‡: {result['system_metrics']['cpu_percent']:.1f}%
- è¨˜æ†¶é«”ä½¿ç”¨ç‡: {result['system_metrics']['memory_percent']:.1f}%
- æ¸¬è©¦é€šéç‡: {result['summary']['passed_tests']}/{result['summary']['total_tests']}

è«‹æª¢æŸ¥ç³»çµ±ç‹€æ…‹ä¸¦æ¡å–ç›¸æ‡‰æªæ–½ã€‚
        """
        )

        print("ğŸš¨ è­¦å ±è§¸ç™¼:")
        for alert in alerts:
            print(f"   - {alert}")

        # Email é€šçŸ¥
        if self.config["notifications"]["email"]["enabled"]:
            self.send_email_alert(alert_message)

        # Slack é€šçŸ¥ (å¦‚æœé…ç½®äº†)
        if self.config["notifications"]["slack"]["enabled"]:
            self.send_slack_alert(alert_message)

    def send_email_alert(self, message):
        """ç™¼é€éƒµä»¶è­¦å ±"""
        try:
            email_config = self.config["notifications"]["email"]

            msg = MimeMultipart()
            msg["From"] = email_config["username"]
            msg["Subject"] = "Multi-Modal Lab æ¸¬è©¦è­¦å ±"

            msg.attach(MimeText(message, "plain"))

            server = smtplib.SMTP(
                email_config["smtp_server"], email_config["smtp_port"]
            )
            server.starttls()
            server.login(email_config["username"], email_config["password"])

            for recipient in email_config["recipients"]:
                msg["To"] = recipient
                server.sendmail(email_config["username"], recipient, msg.as_string())

            server.quit()
            print("   ğŸ“§ éƒµä»¶è­¦å ±å·²ç™¼é€")

        except Exception as e:
            print(f"   âŒ éƒµä»¶ç™¼é€å¤±æ•—: {e}")

    def save_results(self):
        """ä¿å­˜ç›£æ§çµæœ"""
        results_file = Path("test_results/monitoring_history.json")
        results_file.parent.mkdir(exist_ok=True)

        with open(results_file, "w") as f:
            json.dump(self.results_history, f, indent=2)

    def generate_report(self, days=7):
        """ç”Ÿæˆç›£æ§å ±å‘Š"""
        cutoff_date = datetime.now() - timedelta(days=days)

        recent_results = [
            r
            for r in self.results_history
            if datetime.fromisoformat(r["cycle_start"]) > cutoff_date
        ]

        if not recent_results:
            return "æ²’æœ‰è¶³å¤ çš„ç›£æ§è³‡æ–™"

        # è¨ˆç®—çµ±è¨ˆè³‡æ–™
        total_cycles = len(recent_results)
        total_tests = sum(r["summary"]["total_tests"] for r in recent_results)
        total_passed = sum(r["summary"]["passed_tests"] for r in recent_results)

        avg_cpu = (
            sum(r["system_metrics"]["cpu_percent"] for r in recent_results)
            / total_cycles
        )
        avg_memory = (
            sum(r["system_metrics"]["memory_percent"] for r in recent_results)
            / total_cycles
        )

        report = f"""
ğŸ“Š Multi-Modal Lab ç›£æ§å ±å‘Š (éå» {days} å¤©)

ç›£æ§æ‘˜è¦:
- ç›£æ§é€±æœŸ: {total_cycles}
- ç¸½æ¸¬è©¦æ•¸: {total_tests}
- æ¸¬è©¦é€šéç‡: {total_passed/total_tests:.1%}
- å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%
- å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨ç‡: {avg_memory:.1f}%

æœ€è¿‘è­¦å ±:
"""

        # æ·»åŠ æœ€è¿‘çš„è­¦å ±è³‡è¨Š
        alert_count = 0
        for result in recent_results[-10:]:  # æœ€è¿‘10å€‹é€±æœŸ
            if result["summary"]["failed_tests"] > 0:
                alert_count += 1
                report += f"- {result['cycle_start']}: {result['summary']['failed_tests']} å€‹æ¸¬è©¦å¤±æ•—\n"

        if alert_count == 0:
            report += "- ç„¡è­¦å ±è¨˜éŒ„\n"

        return report

    def start_monitoring(self):
        """å•Ÿå‹•æŒçºŒç›£æ§"""
        interval = self.config["monitoring"]["interval_minutes"] * 60

        print(f"ğŸš€ å•Ÿå‹• Multi-Modal Lab æ¸¬è©¦ç›£æ§")
        print(f"   ç›£æ§é–“éš”: {self.config['monitoring']['interval_minutes']} åˆ†é˜")
        print(f"   æ¸¬è©¦å¥—ä»¶: {[t['name'] for t in self.config['test_suites']]}")

        try:
            while True:
                cycle_result = self.run_monitoring_cycle()

                print(
                    f"âœ… ç›£æ§é€±æœŸå®Œæˆ - é€šéç‡: {cycle_result['summary']['passed_tests']}/{cycle_result['summary']['total_tests']}"
                )

                time.sleep(interval)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç›£æ§å·²åœæ­¢")

            # ç”Ÿæˆæœ€çµ‚å ±å‘Š
            report = self.generate_report()
            print("\n" + report)

            return 0


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Multi-Modal Lab Test Monitor")
    parser.add_argument(
        "--config", default="test_monitor_config.json", help="Configuration file"
    )
    parser.add_argument(
        "--once", action="store_true", help="Run monitoring once and exit"
    )
    parser.add_argument("--report", type=int, help="Generate report for last N days")

    args = parser.parse_args()

    monitor = TestMonitor(args.config)

    if args.report:
        report = monitor.generate_report(args.report)
        print(report)
        return 0
    elif args.once:
        result = monitor.run_monitoring_cycle()
        print(
            f"ç›£æ§å®Œæˆ - é€šéç‡: {result['summary']['passed_tests']}/{result['summary']['total_tests']}"
        )
        return 0
    else:
        return monitor.start_monitoring()


if __name__ == "__main__":
    main()
