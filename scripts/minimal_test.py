#!/usr/bin/env python3
# scripts/minimal_test.py
"""
æœ€å°åŒ–æ¸¬è©¦ - é¿å…è¤‡é›œä¾è³´çš„åŸºç¤åŠŸèƒ½æ¸¬è©¦ (already pass)
"""

import os
import sys
from pathlib import Path

# Add project root to path
ROOT_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT_DIR))

# Set up minimal environment
os.environ["AI_CACHE_ROOT"] = str(ROOT_DIR.parent / "ai_warehouse" / "cache")


def test_basic_python():
    """æ¸¬è©¦åŸºæœ¬ Python åŠŸèƒ½"""
    print("ğŸ æ¸¬è©¦åŸºæœ¬ Python åŠŸèƒ½...")

    try:
        import json
        import logging
        import hashlib
        from typing import Dict, Any, Optional
        from pathlib import Path
        from dataclasses import dataclass

        print("   âœ… åŸºæœ¬ Python æ¨¡çµ„æ­£å¸¸")
        return True
    except Exception as e:
        print(f"   âŒ åŸºæœ¬ Python æ¨¡çµ„å¤±æ•—: {e}")
        return False


def test_optional_imports():
    """æ¸¬è©¦å¯é¸çš„é‡å‹ä¾è³´"""
    print("\nğŸ“¦ æ¸¬è©¦å¯é¸ä¾è³´...")

    results = {}

    # Test numpy
    try:
        import numpy as np

        print(f"   âœ… numpy {np.__version__}")
        results["numpy"] = True
    except Exception as e:
        print(f"   âŒ numpy å°å…¥å¤±æ•—: {e}")
        results["numpy"] = False

    # Test torch
    try:
        import torch

        print(f"   âœ… torch {torch.__version__}")
        results["torch"] = True
    except Exception as e:
        print(f"   âŒ torch å°å…¥å¤±æ•—: {e}")
        results["torch"] = False

    # Test transformers
    try:
        import transformers

        print(f"   âœ… transformers {transformers.__version__}")
        results["transformers"] = True
    except Exception as e:
        print(f"   âŒ transformers å°å…¥å¤±æ•—: {e}")
        results["transformers"] = False

    return results


def create_mock_dependencies():
    """å‰µå»º mock ç‰ˆæœ¬çš„é‡å‹ä¾è³´"""
    print("\nğŸ­ å‰µå»º Mock ä¾è³´...")

    # Create mock torch if not available
    if "torch" not in sys.modules:
        import types

        # Mock torch module
        torch_mock = types.ModuleType("torch")
        torch_mock.cuda = types.ModuleType("cuda")
        torch_mock.cuda.is_available = lambda: False
        torch_mock.cuda.empty_cache = lambda: None
        torch_mock.float16 = "torch.float16"
        torch_mock.float32 = "torch.float32"
        torch_mock.bfloat16 = "torch.bfloat16"

        sys.modules["torch"] = torch_mock
        print("   âœ… å‰µå»º torch mock")

    # Mock transformers if needed
    if "transformers" not in sys.modules:
        import types

        transformers_mock = types.ModuleType("transformers")

        # Mock AutoTokenizer
        class MockAutoTokenizer:
            @staticmethod
            def from_pretrained(model_name, **kwargs):
                mock_tokenizer = types.SimpleNamespace()
                mock_tokenizer.pad_token = "[PAD]"
                mock_tokenizer.eos_token = "[EOS]"
                mock_tokenizer.encode = lambda text: [1, 2, 3, 4, 5]  # Mock encoding
                mock_tokenizer.decode = lambda tokens, **kwargs: "mock decoded text"
                return mock_tokenizer

        # Mock AutoModelForCausalLM
        class MockAutoModelForCausalLM:
            @staticmethod
            def from_pretrained(model_name, **kwargs):
                mock_model = types.SimpleNamespace()
                mock_model.generate = lambda **kwargs: [
                    [1, 2, 3, 4, 5, 6]
                ]  # Mock generation
                mock_model.parameters = lambda: [types.SimpleNamespace(device="cpu")]
                return mock_model

        transformers_mock.AutoTokenizer = MockAutoTokenizer
        transformers_mock.AutoModelForCausalLM = MockAutoModelForCausalLM

        sys.modules["transformers"] = transformers_mock
        print("   âœ… å‰µå»º transformers mock")


def test_core_logic_only():
    """åƒ…æ¸¬è©¦æ ¸å¿ƒé‚è¼¯ï¼Œä¸ä¾è³´é‡å‹åº«"""
    print("\nğŸ§  æ¸¬è©¦æ ¸å¿ƒé‚è¼¯...")

    try:
        # Test config loading (should work without heavy deps)
        from core.config import get_config

        config = get_config()
        print("   âœ… é…ç½®æ¨¡çµ„è¼‰å…¥æˆåŠŸ")

        # Test shared cache (basic file operations)
        from core.shared_cache import bootstrap_cache

        cache = bootstrap_cache()
        print("   âœ… å…±äº«å¿«å–åˆå§‹åŒ–æˆåŠŸ")

        # Test exceptions (pure Python)
        from core.exceptions import ModelLoadError, ValidationError

        print("   âœ… ç•°å¸¸é¡åˆ¥è¼‰å…¥æˆåŠŸ")

        return True

    except Exception as e:
        print(f"   âŒ æ ¸å¿ƒé‚è¼¯æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_llm_with_mocks():
    """ä½¿ç”¨ mock æ¸¬è©¦ LLM é‚è¼¯"""
    print("\nğŸ¤– æ¸¬è©¦ LLM é‚è¼¯ï¼ˆä½¿ç”¨ mockï¼‰...")

    try:
        # Test base classes (no heavy deps)
        from core.llm.base import ChatMessage, LLMResponse

        message = ChatMessage(role="user", content="test")
        print("   âœ… ChatMessage å‰µå»ºæˆåŠŸ")

        # Test with mock adapter
        from core.llm.adapter import MockLLMAdapter

        mock_llm = MockLLMAdapter("test-model")
        response = mock_llm.generate("Hello world")
        print(f"   âœ… Mock ç”Ÿæˆ: {response[:50]}...")

        # Test chat
        messages = [ChatMessage(role="user", content="Hello")]
        chat_response = mock_llm.chat(messages)
        print(f"   âœ… Mock å°è©±: {chat_response.content[:50]}...")

        return True

    except Exception as e:
        print(f"   âŒ LLM é‚è¼¯æ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ”¬ æœ€å°åŒ–ç’°å¢ƒæ¸¬è©¦\n")

    # Test basic functionality first
    basic_ok = test_basic_python()
    if not basic_ok:
        print("\nâŒ åŸºæœ¬ Python ç’°å¢ƒæœ‰å•é¡Œï¼Œè«‹æª¢æŸ¥ Python å®‰è£")
        return False

    # Test optional heavy dependencies
    deps = test_optional_imports()

    # Create mocks for missing dependencies
    create_mock_dependencies()

    # Test core logic without heavy deps
    core_ok = test_core_logic_only()

    # Test LLM logic with mocks
    llm_ok = test_llm_with_mocks()

    print("\n" + "=" * 50)
    print("ğŸ“Š æœ€å°åŒ–æ¸¬è©¦çµæœ:")
    print("=" * 50)
    print(f"åŸºæœ¬ Python:     {'âœ…' if basic_ok else 'âŒ'}")
    print(f"NumPy:           {'âœ…' if deps.get('numpy') else 'âŒ'}")
    print(f"PyTorch:         {'âœ…' if deps.get('torch') else 'âŒ'}")
    print(f"Transformers:    {'âœ…' if deps.get('transformers') else 'âŒ'}")
    print(f"æ ¸å¿ƒé‚è¼¯:        {'âœ…' if core_ok else 'âŒ'}")
    print(f"LLM é‚è¼¯:        {'âœ…' if llm_ok else 'âŒ'}")

    if core_ok and llm_ok:
        print("\nâœ¨ æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸ï¼å¯ä»¥ç¹¼çºŒé–‹ç™¼")
        print("\nå»ºè­°:")
        if not all(deps.values()):
            print("- ä¿®å¾©é‡å‹ä¾è³´å®‰è£å•é¡Œ")
            print("- æš«æ™‚å¯ä»¥ä½¿ç”¨ mock æ¨¡å¼é–‹ç™¼")
        return True
    else:
        print("\nâš ï¸ æ ¸å¿ƒåŠŸèƒ½æœ‰å•é¡Œï¼Œéœ€è¦ä¿®å¾©")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nğŸ’¥ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
