#!/usr/bin/env python3
# scripts/run_full_test_suite.py
"""
å®Œæ•´æ¸¬è©¦å¥—ä»¶åŸ·è¡Œå™¨
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path
import time
import json


def run_command(cmd, timeout=300):
    """åŸ·è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
    print(f"ğŸ”„ Running: {' '.join(cmd)}")

    try:
        result = subprocess.run(
            cmd, capture_output=True, text=True, timeout=timeout, check=False
        )

        return {
            "success": result.returncode == 0,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode,
        }

    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "stdout": "",
            "stderr": f"Command timed out after {timeout}s",
            "returncode": -1,
        }


def main():
    parser = argparse.ArgumentParser(description="Run comprehensive backend tests")
    parser.add_argument("--quick", action="store_true", help="Run quick tests only")
    parser.add_argument(
        "--performance", action="store_true", help="Include performance tests"
    )
    parser.add_argument(
        "--coverage", action="store_true", help="Generate coverage report"
    )
    parser.add_argument("--parallel", action="store_true", help="Run tests in parallel")
    parser.add_argument(
        "--output-dir", default="test_results", help="Output directory for results"
    )

    args = parser.parse_args()

    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)

    print("ğŸ§ª Multi-Modal Lab Comprehensive Test Suite")
    print("=" * 50)

    # æ¸¬è©¦éšæ®µé…ç½®
    test_phases = [
        {
            "name": "å¥åº·æª¢æŸ¥",
            "command": [sys.executable, "scripts/health_check.py"],
            "required": True,
        },
        {
            "name": "ä»£ç¢¼å“è³ªæª¢æŸ¥",
            "command": ["ruff", "check", "backend/", "tests/"],
            "required": True,
        },
        {
            "name": "æ ¼å¼æª¢æŸ¥",
            "command": ["black", "--check", "backend/", "tests/"],
            "required": True,
        },
        {
            "name": "å–®å…ƒæ¸¬è©¦",
            "command": [
                sys.executable,
                "-m",
                "pytest",
                "tests/test_core_modules.py",
                "-v",
            ],
            "required": True,
        },
        {
            "name": "æ•´åˆæ¸¬è©¦",
            "command": [
                sys.executable,
                "-m",
                "pytest",
                "tests/test_api_endpoints.py",
                "-v",
            ],
            "required": True,
        },
    ]

    if not args.quick:
        test_phases.extend(
            [
                {
                    "name": "ç«¯åˆ°ç«¯æ¸¬è©¦",
                    "command": [
                        sys.executable,
                        "-m",
                        "pytest",
                        "tests/test_e2e_workflows.py",
                        "-v",
                    ],
                    "required": False,
                },
                {
                    "name": "å¯é æ€§æ¸¬è©¦",
                    "command": [
                        sys.executable,
                        "-m",
                        "pytest",
                        "tests/test_reliability.py",
                        "-v",
                    ],
                    "required": False,
                },
            ]
        )

    if args.performance:
        test_phases.append(
            {
                "name": "æ€§èƒ½æ¸¬è©¦",
                "command": [
                    sys.executable,
                    "-m",
                    "pytest",
                    "tests/test_performance.py",
                    "-v",
                    "-m",
                    "slow",
                ],
                "required": False,
            }
        )

    # ä¸¦è¡Œæ¸¬è©¦é¸é …
    if args.parallel:
        for phase in test_phases:
            if "pytest" in phase["command"]:
                phase["command"].extend(["-n", "auto"])

    # è¦†è“‹ç‡é¸é …
    if args.coverage:
        for phase in test_phases:
            if "pytest" in phase["command"]:
                phase["command"].extend(
                    ["--cov=backend", "--cov-report=html", "--cov-report=term"]
                )

    # åŸ·è¡Œæ¸¬è©¦éšæ®µ
    results = {}
    total_start = time.time()

    for phase in test_phases:
        phase_start = time.time()
        print(f"\nğŸ” {phase['name']}")
        print("-" * 30)

        result = run_command(phase["command"], timeout=600)
        phase_duration = time.time() - phase_start

        results[phase["name"]] = {
            "success": result["success"],
            "duration": phase_duration,
            "required": phase["required"],
            "output": result["stdout"],
            "errors": result["stderr"],
        }

        if result["success"]:
            print(f"âœ… {phase['name']} é€šé ({phase_duration:.1f}s)")
        else:
            print(f"âŒ {phase['name']} å¤±æ•— ({phase_duration:.1f}s)")
            if phase["required"]:
                print(f"ğŸš¨ å¿…è¦éšæ®µå¤±æ•—ï¼Œåœæ­¢æ¸¬è©¦")
                break
            else:
                print(f"âš ï¸  å¯é¸éšæ®µå¤±æ•—ï¼Œç¹¼çºŒåŸ·è¡Œ")

        # è¼¸å‡ºéšæ®µçµæœåˆ°æ–‡ä»¶
        phase_output_file = output_dir / f"{phase['name'].replace(' ', '_')}.log"
        with open(phase_output_file, "w", encoding="utf-8") as f:
            f.write(f"=== {phase['name']} ===\n")
            f.write(f"Command: {' '.join(phase['command'])}\n")
            f.write(f"Duration: {phase_duration:.2f}s\n")
            f.write(f"Return Code: {result['returncode']}\n")
            f.write(f"Success: {result['success']}\n\n")
            f.write("=== STDOUT ===\n")
            f.write(result["stdout"])
            f.write("\n\n=== STDERR ===\n")
            f.write(result["stderr"])

    total_duration = time.time() - total_start

    # ç”Ÿæˆç¸½çµå ±å‘Š
    print(f"\n{'='*50}")
    print("ğŸ“Š æ¸¬è©¦ç¸½çµå ±å‘Š")
    print(f"{'='*50}")

    passed_count = sum(1 for r in results.values() if r["success"])
    total_count = len(results)
    required_failed = any(not r["success"] and r["required"] for r in results.values())

    print(f"ç¸½åŸ·è¡Œæ™‚é–“: {total_duration:.1f}s")
    print(f"æ¸¬è©¦éšæ®µ: {passed_count}/{total_count} é€šé")

    for name, result in results.items():
        status = "âœ…" if result["success"] else "âŒ"
        required_mark = "ğŸ”´" if result["required"] else "ğŸ”µ"
        print(f"  {status} {required_mark} {name}: {result['duration']:.1f}s")

    # ä¿å­˜è©³ç´°å ±å‘Š
    detailed_report = {
        "summary": {
            "total_duration": total_duration,
            "total_phases": total_count,
            "passed_phases": passed_count,
            "failed_phases": total_count - passed_count,
            "required_failed": required_failed,
        },
        "phases": results,
        "timestamp": time.time(),
        "config": {
            "quick": args.quick,
            "performance": args.performance,
            "coverage": args.coverage,
            "parallel": args.parallel,
        },
    }

    report_file = output_dir / "comprehensive_test_report.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(detailed_report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“‹ è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_file}")

    # æœ€çµ‚çµæœ
    if required_failed:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: å¿…è¦éšæ®µæœªé€šé")
        return 1
    elif passed_count == total_count:
        print(f"\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šé! ç³»çµ±å°±ç·’")
        return 0
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†å¯é¸æ¸¬è©¦å¤±æ•—ï¼Œä½†ç³»çµ±åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        return 0


if __name__ == "__main__":
    main()
