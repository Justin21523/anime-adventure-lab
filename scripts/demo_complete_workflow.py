#!/usr/bin/env python3
"""
SagaForge Complete Workflow Demo
Demonstrates the full end-to-end pipeline: RAG â†’ LLM â†’ T2I â†’ VLM â†’ LoRA
"""

import os
import sys
import time
import requests
import json
import zipfile
import tempfile
from pathlib import Path
from typing import Dict, Any

# Shared cache bootstrap
AI_CACHE_ROOT = os.getenv("AI_CACHE_ROOT", "../ai_warehouse/cache")
for k, v in {
    "HF_HOME": f"{AI_CACHE_ROOT}/hf",
    "TRANSFORMERS_CACHE": f"{AI_CACHE_ROOT}/hf/transformers",
    "TORCH_HOME": f"{AI_CACHE_ROOT}/torch",
}.items():
    os.environ[k] = v
    Path(v).mkdir(parents=True, exist_ok=True)


class SagaForgeDemo:
    """Complete SagaForge workflow demonstration"""

    def __init__(self, api_base: str = "http://localhost:8000"):
        self.api_base = api_base
        self.session = requests.Session()
        self.session.timeout = 60

        # Demo data
        self.world_id = "demo_neo_taipei"
        self.character_id = "alice_demo"

        print(f"ğŸ® SagaForge Demo initialized")
        print(f"ğŸ“¡ API Base: {api_base}")
        print(f"ğŸŒ World ID: {self.world_id}")
        print(f"ğŸ‘¤ Character: {self.character_id}")

    def check_health(self) -> bool:
        """Check if SagaForge API is healthy"""
        print("\nğŸ¥ Health Check")
        print("-" * 30)

        try:
            response = self.session.get(f"{self.api_base}/healthz")
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… API Status: {data.get('status', 'unknown')}")
                print(f"ğŸ“Š Version: {data.get('version', 'unknown')}")
                return True
            else:
                print(f"âŒ Health check failed: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ Health check error: {e}")
            return False

    def create_demo_worldpack(self) -> Path:
        """Create a demo worldpack for testing"""
        print("\nğŸ“¦ Creating Demo Worldpack")
        print("-" * 30)

        temp_dir = Path(tempfile.mkdtemp())
        worldpack_path = temp_dir / "neo_taipei_demo.zip"

        # Demo world content
        characters_yaml = f"""
characters:
  {self.character_id}:
    name: "Alice Chen"
    description: "ä¸€ä½å‹‡æ•¢çš„å¹´è¼•ç¨‹å¼è¨­è¨ˆå¸«ï¼Œä¾†è‡ªæ–°å°åŒ—å¸‚"
    appearance: "çŸ­é»‘é«®ï¼Œè—è‰²çœ¼ç›ï¼Œä¼‘é–’æœè£ï¼ŒèƒŒè‘—ç­†è¨˜å‹é›»è…¦åŒ…"
    personality: "å¥½å¥‡å¿ƒå¼·ï¼Œæ„å¿—å …å®šï¼Œç²¾é€šç§‘æŠ€"
    background: |
      Alice å‡ºç”Ÿæ–¼æ–°å°åŒ—å¸‚ï¼Œæ˜¯ä¸€åè‡ªç”±å·¥ä½œçš„è»Ÿé«”é–‹ç™¼è€…ã€‚
      å¥¹å°ˆç²¾æ–¼ AI ç³»çµ±é–‹ç™¼ï¼Œå¤¢æƒ³å‰µé€ èƒ½æ”¹è®Šä¸–ç•Œçš„æŠ€è¡“ã€‚
      åœ¨è³½åšé¾å…‹çš„åŸå¸‚ä¸­ï¼Œå¥¹å°‹æ‰¾è‘—çœŸç›¸èˆ‡æ­£ç¾©ã€‚
    relationships:
      mentor: "Dr. Lin - å¥¹çš„ AI ç ”ç©¶å°å¸«"
      friend: "Bobby - é§­å®¢å¤¥ä¼´"
    goals:
      - "æ­ç™¼ä¼æ¥­çš„ AI é™°è¬€"
      - "ä¿è­·å¸‚æ°‘å…å— AI ç›£æ§"
      - "é–‹ç™¼é–‹æº AI å·¥å…·"
"""

        scenes_yaml = """
scenes:
  downtown:
    title: "æ–°å°åŒ—å¸‚ä¸­å¿ƒå€"
    description: "éœ“è™¹ç‡ˆé–ƒçˆçš„å•†æ¥­å€ï¼Œåˆ°è™•éƒ½æ˜¯å…¨æ¯å»£å‘Šå’Œ AI åŠ©æ‰‹"
    location: "æ–°å°åŒ—å¸‚ä¸­å¿ƒ"
    atmosphere: "è³½åšé¾å…‹ï¼Œæœªä¾†æ„Ÿï¼Œç§‘æŠ€èˆ‡å‚³çµ±äº¤è"
    details: |
      é«˜è³çš„æ‘©å¤©å¤§æ¨“ç›´æ’é›²éœ„ï¼Œå…¨æ¯æŠ•å½±çš„å»£å‘Šç‰Œæ‡¸æµ®åœ¨ç©ºä¸­ã€‚
      è¡—é“ä¸Šè¡ŒäººåŒ†å¿™ï¼Œæ¯å€‹äººéƒ½å¸¶è‘— AR çœ¼é¡æˆ–ç¥ç¶“æ¥å£è¨­å‚™ã€‚
      å‚³çµ±çš„å¤œå¸‚å°æ”¤å’Œé«˜ç§‘æŠ€å•†åº—ä¸¦è‚©è€Œç«‹ã€‚
    npcs:
      - "è¡—é ­å°è²© - è²©è³£æ”¹è£éçš„ AI æ™¶ç‰‡"
      - "ä¼æ¥­ä¿å®‰ - ç›£è¦–å¯ç–‘æ´»å‹•"
      - "åœ°ä¸‹é§­å®¢ - åœ¨æš—ç¶²ä¸­äº¤æ˜“è³‡è¨Š"

  lab:
    title: "åœ°ä¸‹å¯¦é©—å®¤"
    description: "éš±è—åœ¨åŸå¸‚åœ°ä¸‹çš„ç§˜å¯† AI ç ”ç©¶è¨­æ–½"
    location: "æ–°å°åŒ—åœ°ä¸‹åŸ"
    atmosphere: "ç¥ç§˜ï¼Œé«˜ç§‘æŠ€ï¼Œç•¥é¡¯å±éšª"
    details: |
      é€™è£¡æ˜¯ Alice å’Œå¥¹çš„åœ˜éšŠé€²è¡Œ AI ç ”ç©¶çš„ç§˜å¯†åŸºåœ°ã€‚
      ç‰†ä¸Šæ›æ»¿äº†é‡å­è¨ˆç®—æ©Ÿå’Œç¥ç¶“ç¶²è·¯åœ–è¡¨ã€‚
      ç©ºæ°£ä¸­ç€°æ¼«è‘—æœå‹™å™¨æ•£ç†±çš„å—¡å—¡è²ã€‚
"""

        lorebook_md = """
# æ–°å°åŒ—å¸‚ä¸–ç•Œè§€

## åŸå¸‚èƒŒæ™¯

æ–°å°åŒ—å¸‚æ˜¯ 2089 å¹´çš„è³½åšé¾å…‹å¤§éƒ½æœƒï¼Œç§‘æŠ€èˆ‡å‚³çµ±æ–‡åŒ–äº¤èã€‚äººå·¥æ™ºæ…§å·²ç¶“æ·±å…¥æ—¥å¸¸ç”Ÿæ´»çš„æ¯å€‹è§’è½ã€‚

### æŠ€è¡“è¨­å®š

- **AI åŠ©æ‰‹**: æ¯å€‹å¸‚æ°‘éƒ½æœ‰å€‹äºº AI é™ªä¼´ï¼Œè™•ç†æ—¥å¸¸äº‹å‹™
- **ç¥ç¶“æ¥å£**: ç›´æ¥å¤§è…¦-é›»è…¦ä»‹é¢æŠ€è¡“æ™®åŠ
- **å…¨æ¯æŠ€è¡“**: ç«‹é«”æŠ•å½±å»£å‘Šå’Œå¨›æ¨‚éš¨è™•å¯è¦‹
- **é‡å­ç¶²è·¯**: è¶…é«˜é€Ÿè³‡æ–™å‚³è¼¸ç¶²è·¯

### ç¤¾æœƒçµæ§‹

- **ä¼æ¥­è²¡åœ˜**: æ§åˆ¶å¤§éƒ¨åˆ† AI æŠ€è¡“çš„å·¨å‹ä¼æ¥­
- **è‡ªç”±é§­å®¢**: å°æŠ—ä¼æ¥­ç›£æ§çš„åœ°ä¸‹çµ„ç¹”
- **æ™®é€šå¸‚æ°‘**: åœ¨é«˜ç§‘æŠ€ç¤¾æœƒä¸­åŠªåŠ›ç”Ÿå­˜çš„äººå€‘

### è¡çªé»

- **éš±ç§ vs ä¾¿åˆ©**: AI ç›£æ§å¸¶ä¾†ä¾¿åˆ©ä½†ä¾µçŠ¯éš±ç§
- **äººé¡ vs æ©Ÿå™¨**: AI é€æ¼¸å–ä»£äººé¡å·¥ä½œ
- **ä¼æ¥­ vs å€‹äºº**: å¤§ä¼æ¥­å£Ÿæ–·æŠ€è¡“è³‡æº

## é‡è¦çµ„ç¹”

### TechCorp ä¼æ¥­é›†åœ˜
- æœ€å¤§çš„ AI æŠ€è¡“å…¬å¸
- æ§åˆ¶åŸå¸‚å¤§éƒ¨åˆ†åŸºç¤è¨­æ–½
- è¢«æŒ‡æ§é€²è¡Œéæ³• AI å¯¦é©—

### è‡ªç”±ä»£ç¢¼è¯ç›Ÿ
- Alice æ‰€å±¬çš„é§­å®¢çµ„ç¹”
- è‡´åŠ›æ–¼é–‹æº AI æŠ€è¡“
- å°æŠ—ä¼æ¥­å£Ÿæ–·

## é—œéµé“å…·

### è—è‰²å¾½ç« 
- ç¥ç§˜çš„é‡å­åŠ å¯†è¨­å‚™
- å¯ä»¥çªç ´ä¼æ¥­ AI é˜²ç«ç‰†
- åªæœ‰åœ¨ç‰¹å®šæ™‚é–“æ‰èƒ½å•Ÿå‹•

### ç¥ç¶“æ¥å£é ­ç›”
- å¢å¼·äººé¡èªçŸ¥èƒ½åŠ›
- å…è¨±ç›´æ¥æ§åˆ¶ AI ç³»çµ±
- å­˜åœ¨è¢«é§­å®¢å…¥ä¾µçš„é¢¨éšª
"""

        style_toml = """
[visual_style]
art_style = "cyberpunk anime"
color_palette = ["neon blue", "electric pink", "dark purple", "silver"]
lighting = "neon lighting, dramatic shadows"
mood = "futuristic, mysterious, tech-noir"

[narrative_style]
tone = "adventure with mystery elements"
perspective = "second_person"
language = "traditional_chinese"
pacing = "medium, with action scenes"

[generation_presets]
character_portrait = "anime style, cyberpunk character, detailed face, neon lighting"
scene_background = "cyberpunk cityscape, neon lights, futuristic architecture"
action_scene = "dynamic pose, dramatic lighting, motion blur effects"
"""

        # Create worldpack ZIP
        with zipfile.ZipFile(worldpack_path, "w", zipfile.ZIP_DEFLATED) as zf:
            zf.writestr("characters.yaml", characters_yaml)
            zf.writestr("scenes.yaml", scenes_yaml)
            zf.writestr("lorebook.md", lorebook_md)
            zf.writestr("style.toml", style_toml)

        print(f"âœ… Demo worldpack created: {worldpack_path}")
        print(f"ğŸ“ Size: {worldpack_path.stat().st_size / 1024:.1f} KB")

        return worldpack_path

    def upload_worldpack(self) -> bool:
        """Upload worldpack and test RAG ingestion"""
        print("\nğŸ“š RAG Ingestion Test")
        print("-" * 30)

        worldpack_path = self.create_demo_worldpack()

        try:
            with open(worldpack_path, "rb") as f:
                files = {"file": ("neo_taipei_demo.zip", f, "application/zip")}
                data = {
                    "world_id": self.world_id,
                    "license": "CC-BY-SA-4.0",
                    "overwrite": "true",
                }

                print("ğŸ“¤ Uploading worldpack...")
                response = self.session.post(
                    f"{self.api_base}/rag/upload", files=files, data=data
                )

            if response.status_code == 200:
                result = response.json()
                doc_count = len(result.get("doc_ids", []))
                chunk_count = result.get("total_chunks", 0)

                print(f"âœ… Upload successful")
                print(f"ğŸ“„ Documents: {doc_count}")
                print(f"ğŸ§© Chunks: {chunk_count}")

                return True
            else:
                print(f"âŒ Upload failed: {response.status_code}")
                print(f"ğŸ“‹ Response: {response.text}")
                return False

        except Exception as e:
            print(f"âŒ Upload error: {e}")
            return False

    def test_rag_retrieval(self) -> Dict[str, Any]:
        """Test RAG retrieval with various queries"""
        print("\nğŸ” RAG Retrieval Test")
        print("-" * 30)

        test_queries = [
            "å‘Šè¨´æˆ‘é—œæ–¼ Alice Chen çš„èƒŒæ™¯",
            "æ–°å°åŒ—å¸‚çš„ç§‘æŠ€è¨­å®šæ˜¯ä»€éº¼ï¼Ÿ",
            "è—è‰²å¾½ç« æœ‰ä»€éº¼ç‰¹æ®ŠåŠŸèƒ½ï¼Ÿ",
            "TechCorp ä¼æ¥­é›†åœ˜çš„è§’è‰²æ˜¯ä»€éº¼ï¼Ÿ",
        ]

        retrieval_results = {}

        for query in test_queries:
            print(f"â“ Query: {query}")

            try:
                payload = {
                    "world_id": self.world_id,
                    "query": query,
                    "top_k": 3,
                    "rerank": True,
                }

                response = self.session.post(
                    f"{self.api_base}/rag/retrieve", json=payload
                )

                if response.status_code == 200:
                    result = response.json()
                    chunks = result.get("chunks", [])

                    print(f"âœ… Found {len(chunks)} relevant chunks")
                    if chunks:
                        top_chunk = chunks[0]
                        print(f"ğŸ“ Top result: {top_chunk['text'][:100]}...")
                        print(f"ğŸ¯ Score: {top_chunk.get('score', 0):.3f}")

                    retrieval_results[query] = result
                else:
                    print(f"âŒ Retrieval failed: {response.status_code}")

            except Exception as e:
                print(f"âŒ Retrieval error: {e}")

            print()

        return retrieval_results

    def test_llm_conversation(self) -> Dict[str, Any]:
        """Test LLM conversation with RAG context"""
        print("\nğŸ’¬ LLM Conversation Test")
        print("-" * 30)

        conversation_scenarios = [
            {
                "message": "æˆ‘æƒ³äº†è§£ Alice çš„æ•…äº‹ï¼Œå¥¹ç¾åœ¨åœ¨å“ªè£¡ï¼Ÿ",
                "context": "story_introduction",
            },
            {"message": "æˆ‘æƒ³æ¢ç´¢æ–°å°åŒ—å¸‚ä¸­å¿ƒå€", "context": "scene_exploration"},
            {"message": "å‘Šè¨´æˆ‘æ›´å¤šé—œæ–¼è—è‰²å¾½ç« çš„è³‡è¨Š", "context": "item_inquiry"},
        ]

        conversation_results = {}

        for i, scenario in enumerate(conversation_scenarios, 1):
            print(f"ğŸ’­ Scenario {i}: {scenario['context']}")
            print(f"ğŸ‘¤ Player: {scenario['message']}")

            try:
                payload = {
                    "message": scenario["message"],
                    "world_id": self.world_id,
                    "character_id": self.character_id,
                    "use_rag": True,
                    "max_tokens": 300,
                    "temperature": 0.7,
                }

                response = self.session.post(f"{self.api_base}/llm/turn", json=payload)

                if response.status_code == 200:
                    result = response.json()

                    print(f"ğŸ¤– Narration: {result.get('narration', '')}")

                    choices = result.get("choices", [])
                    if choices:
                        print(f"ğŸ® Choices:")
                        for j, choice in enumerate(choices[:3], 1):
                            print(f"   {j}. {choice.get('text', '')}")

                    citations = result.get("citations", [])
                    print(f"ğŸ“š Citations: {len(citations)} sources referenced")

                    conversation_results[scenario["context"]] = result

                else:
                    print(f"âŒ Conversation failed: {response.status_code}")

            except Exception as e:
                print(f"âŒ Conversation error: {e}")

            print()

        return conversation_results

    def test_image_generation(self) -> Dict[str, Any]:
        """Test T2I image generation"""
        print("\nğŸ¨ Image Generation Test")
        print("-" * 30)

        generation_scenarios = [
            {
                "name": "character_portrait",
                "prompt": "anime style portrait of Alice Chen, short black hair, blue eyes, casual clothes, cyberpunk background",
                "style": "anime_portrait",
            },
            {
                "name": "scene_background",
                "prompt": "cyberpunk cityscape, neon lights, futuristic buildings, new taipei city, night scene",
                "style": "cyberpunk_scene",
            },
            {
                "name": "action_scene",
                "prompt": "anime girl hacking computer, dramatic lighting, neon glow, focused expression",
                "style": "action_anime",
            },
        ]

        generation_results = {}

        for scenario in generation_scenarios:
            print(f"ğŸ–¼ï¸ Generating: {scenario['name']}")
            print(f"ğŸ“ Prompt: {scenario['prompt']}")

            try:
                payload = {
                    "prompt": scenario["prompt"],
                    "negative_prompt": "blurry, low quality, distorted, extra limbs",
                    "width": 768,
                    "height": 768,
                    "steps": 25,
                    "cfg_scale": 7.5,
                    "seed": 42,  # Fixed seed for reproducibility
                    "style_preset": scenario.get("style"),
                }

                start_time = time.time()
                response = self.session.post(
                    f"{self.api_base}/t2i/generate", json=payload
                )
                generation_time = time.time() - start_time

                if response.status_code == 200:
                    result = response.json()
                    image_path = result.get("image_path")

                    print(f"âœ… Generated successfully in {generation_time:.1f}s")
                    print(f"ğŸ’¾ Image saved: {image_path}")

                    # Verify image file exists
                    if image_path and Path(image_path).exists():
                        file_size = Path(image_path).stat().st_size / 1024
                        print(f"ğŸ“ File size: {file_size:.1f} KB")

                    generation_results[scenario["name"]] = result

                else:
                    print(f"âŒ Generation failed: {response.status_code}")
                    print(f"ğŸ“‹ Response: {response.text}")

            except Exception as e:
                print(f"âŒ Generation error: {e}")

            print()

        return generation_results

    def test_controlnet_pose(self) -> Dict[str, Any]:
        """Test ControlNet pose generation"""
        print("\nğŸ•º ControlNet Pose Test")
        print("-" * 30)

        # Simple pose keypoints (standing pose)
        pose_keypoints = [
            {"x": 384, "y": 150, "confidence": 0.9, "name": "head"},
            {"x": 384, "y": 200, "confidence": 0.9, "name": "neck"},
            {"x": 384, "y": 350, "confidence": 0.9, "name": "torso"},
            {"x": 300, "y": 280, "confidence": 0.8, "name": "left_shoulder"},
            {"x": 468, "y": 280, "confidence": 0.8, "name": "right_shoulder"},
            {"x": 250, "y": 400, "confidence": 0.8, "name": "left_hand"},
            {"x": 518, "y": 400, "confidence": 0.8, "name": "right_hand"},
            {"x": 350, "y": 500, "confidence": 0.9, "name": "left_hip"},
            {"x": 418, "y": 500, "confidence": 0.9, "name": "right_hip"},
            {"x": 350, "y": 650, "confidence": 0.9, "name": "left_knee"},
            {"x": 418, "y": 650, "confidence": 0.9, "name": "right_knee"},
            {"x": 350, "y": 750, "confidence": 0.9, "name": "left_foot"},
            {"x": 418, "y": 750, "confidence": 0.9, "name": "right_foot"},
        ]

        try:
            payload = {
                "prompt": "anime style Alice Chen, confident pose, cyberpunk outfit",
                "negative_prompt": "blurry, distorted anatomy",
                "controlnet_type": "openpose",
                "pose_keypoints": pose_keypoints,
                "width": 768,
                "height": 768,
                "steps": 20,
                "cfg_scale": 7.0,
                "seed": 123,
            }

            print("ğŸ¯ Generating pose-controlled image...")
            start_time = time.time()

            response = self.session.post(
                f"{self.api_base}/t2i/controlnet/pose", json=payload
            )

            generation_time = time.time() - start_time

            if response.status_code == 200:
                result = response.json()
                image_path = result.get("image_path")

                print(f"âœ… ControlNet generation successful in {generation_time:.1f}s")
                print(f"ğŸ’¾ Controlled image saved: {image_path}")

                return result
            else:
                print(f"âŒ ControlNet generation failed: {response.status_code}")
                return {}

        except Exception as e:
            print(f"âŒ ControlNet error: {e}")
            return {}

    def test_vlm_analysis(self, image_paths: list) -> Dict[str, Any]:
        """Test VLM image analysis"""
        print("\nğŸ‘ï¸ VLM Analysis Test")
        print("-" * 30)

        vlm_results = {}

        for i, image_path in enumerate(image_paths[:2]):  # Limit to 2 images
            if not image_path or not Path(image_path).exists():
                continue

            print(f"ğŸ” Analyzing image {i+1}: {Path(image_path).name}")

            try:
                # Caption generation
                with open(image_path, "rb") as f:
                    files = {"image": f}
                    data = {"detail_level": "medium"}

                    response = self.session.post(
                        f"{self.api_base}/vlm/caption", files=files, data=data
                    )

                if response.status_code == 200:
                    caption_result = response.json()
                    caption = caption_result.get("caption", "")

                    print(f"ğŸ“ Caption: {caption}")

                    # Consistency check
                    consistency_payload = {
                        "image_path": image_path,
                        "expected_tags": ["alice", "anime", "cyberpunk", "girl"],
                        "world_id": self.world_id,
                    }

                    response = self.session.post(
                        f"{self.api_base}/vlm/check_consistency",
                        json=consistency_payload,
                    )

                    if response.status_code == 200:
                        consistency_result = response.json()
                        score = consistency_result.get("consistency_score", 0)

                        print(f"ğŸ¯ Consistency score: {score:.3f}")

                        vlm_results[f"image_{i+1}"] = {
                            "caption": caption,
                            "consistency_score": score,
                        }

                else:
                    print(f"âŒ VLM analysis failed: {response.status_code}")

            except Exception as e:
                print(f"âŒ VLM error: {e}")

            print()

        return vlm_results

    def test_batch_generation(self) -> Dict[str, Any]:
        """Test batch generation workflow"""
        print("\nâš¡ Batch Generation Test")
        print("-" * 30)

        # Create batch job
        batch_prompts = [
            "Alice in cyberpunk alley, neon signs, rain",
            "Alice at computer terminal, focused, hacking",
            "Alice meeting with underground hackers, secret meeting",
        ]

        try:
            payload = {
                "world_id": self.world_id,
                "job_type": "image_generation",
                "config": {
                    "prompts": batch_prompts,
                    "style_preset": "cyberpunk_anime",
                    "generation_params": {
                        "width": 512,
                        "height": 512,
                        "steps": 15,
                        "seed_policy": "random",
                    },
                },
            }

            print("ğŸ“¤ Submitting batch job...")
            response = self.session.post(f"{self.api_base}/batch/submit", json=payload)

            if response.status_code == 200:
                result = response.json()
                batch_id = result.get("batch_id")

                print(f"âœ… Batch job submitted: {batch_id}")
                print(f"ğŸ“Š Total tasks: {result.get('total_tasks', 0)}")

                # Monitor progress
                return self.monitor_batch_progress(batch_id)
            else:
                print(f"âŒ Batch submission failed: {response.status_code}")
                return {}

        except Exception as e:
            print(f"âŒ Batch error: {e}")
            return {}

    def monitor_batch_progress(self, batch_id: str) -> Dict[str, Any]:
        """Monitor batch job progress"""
        print(f"â³ Monitoring batch progress: {batch_id}")

        max_wait_time = 300  # 5 minutes max
        start_time = time.time()

        while time.time() - start_time < max_wait_time:
            try:
                response = self.session.get(f"{self.api_base}/batch/{batch_id}/status")

                if response.status_code == 200:
                    status = response.json()

                    progress = status.get("progress", {})
                    completed = progress.get("completed", 0)
                    total = progress.get("total", 0)
                    failed = progress.get("failed", 0)

                    print(f"ğŸ“ˆ Progress: {completed}/{total} (failed: {failed})")

                    if status.get("status") == "completed":
                        print("ğŸ‰ Batch job completed!")
                        return status
                    elif status.get("status") == "failed":
                        print("ğŸ’¥ Batch job failed!")
                        return status

                    time.sleep(10)  # Wait 10 seconds before next check
                else:
                    print(f"âŒ Status check failed: {response.status_code}")
                    break

            except Exception as e:
                print(f"âŒ Status check error: {e}")
                break

        print("â° Batch monitoring timeout")
        return {}

    def test_lora_training_submission(self) -> Dict[str, Any]:
        """Test LoRA training job submission"""
        print("\nğŸ“ LoRA Training Test")
        print("-" * 30)

        try:
            training_config = {
                "base_model": "runwayml/stable-diffusion-v1-5",
                "character_name": self.character_id,
                "dataset_config": {
                    "data_source": "demo_dataset",
                    "character_tags": ["alice_chen", "cyberpunk", "programmer"],
                    "min_images": 10,
                },
                "training_config": {
                    "rank": 16,
                    "learning_rate": 1e-4,
                    "max_steps": 500,  # Short training for demo
                    "batch_size": 1,
                    "resolution": 512,
                    "save_every": 100,
                },
                "output_name": f"{self.character_id}_demo_v1",
                "notes": "Demo LoRA training run",
            }

            print("ğŸš€ Submitting LoRA training job...")
            response = self.session.post(
                f"{self.api_base}/finetune/lora", json=training_config
            )

            if response.status_code == 200:
                result = response.json()
                job_id = result.get("job_id")

                print(f"âœ… Training job submitted: {job_id}")
                print(
                    f"â±ï¸ Estimated time: {result.get('estimated_time', 0)/60:.1f} minutes"
                )

                return result
            else:
                print(f"âŒ Training submission failed: {response.status_code}")
                return {}

        except Exception as e:
            print(f"âŒ Training submission error: {e}")
            return {}

    def test_monitoring_endpoints(self) -> Dict[str, Any]:
        """Test system monitoring endpoints"""
        print("\nğŸ“Š System Monitoring Test")
        print("-" * 30)

        monitoring_results = {}

        # Test health endpoint
        try:
            response = self.session.get(f"{self.api_base}/monitoring/health")
            if response.status_code == 200:
                health_data = response.json()

                print("ğŸ¥ Service Health:")
                for service, status in health_data.items():
                    status_icon = "âœ…" if status.get("status") == "healthy" else "âŒ"
                    latency = status.get("latency_ms", 0)
                    print(
                        f"   {status_icon} {service}: {status.get('status')} ({latency:.1f}ms)"
                    )

                monitoring_results["health"] = health_data

        except Exception as e:
            print(f"âŒ Health monitoring error: {e}")

        # Test metrics endpoint
        try:
            response = self.session.get(f"{self.api_base}/monitoring/metrics")
            if response.status_code == 200:
                metrics = response.json()

                print("\nğŸ“ˆ System Metrics:")
                print(f"   ğŸ’» CPU: {metrics.get('cpu_percent', 0):.1f}%")
                print(f"   ğŸ§  Memory: {metrics.get('memory_percent', 0):.1f}%")
                print(f"   ğŸ’¾ Disk: {metrics.get('disk_percent', 0):.1f}%")

                gpu_info = metrics.get("gpu_info")
                if gpu_info and gpu_info["devices"]:
                    gpu = gpu_info["devices"][0]
                    print(
                        f"   ğŸ® GPU: {gpu.get('utilization_percent', 0):.1f}% ({gpu.get('name', 'Unknown')})"
                    )

                print(f"   ğŸ‘· Active workers: {metrics.get('active_workers', 0)}")
                print(f"   ğŸ“‹ Queue depth: {metrics.get('queue_depth', 0)}")

                monitoring_results["metrics"] = metrics

        except Exception as e:
            print(f"âŒ Metrics monitoring error: {e}")

        return monitoring_results

    def generate_demo_report(self, results: Dict[str, Any]) -> str:
        """Generate comprehensive demo report"""
        report = f"""
# SagaForge Demo Report
**Generated:** {time.strftime('%Y-%m-%d %H:%M:%S')}
**World ID:** {self.world_id}
**Character:** {self.character_id}

## ğŸ¯ Demo Summary

"""

        # Check which tests passed
        passed_tests = []
        failed_tests = []

        for test_name, result in results.items():
            if result and isinstance(result, dict) and result.get("success", True):
                passed_tests.append(test_name)
            else:
                failed_tests.append(test_name)

        report += f"âœ… **Passed Tests:** {len(passed_tests)}\n"
        report += f"âŒ **Failed Tests:** {len(failed_tests)}\n\n"

        # Detailed results
        if "rag_retrieval" in results:
            report += "## ğŸ“š RAG Retrieval Results\n"
            rag_data = results["rag_retrieval"]
            report += f"- Tested {len(rag_data)} queries\n"
            report += f"- Average chunks retrieved: {sum(len(r.get('chunks', [])) for r in rag_data.values()) / len(rag_data):.1f}\n\n"

        if "image_generation" in results:
            report += "## ğŸ¨ Image Generation Results\n"
            img_data = results["image_generation"]
            report += f"- Generated {len(img_data)} images\n"
            for name, data in img_data.items():
                if data.get("image_path"):
                    report += f"- {name}: âœ… Success\n"
            report += "\n"

        if "vlm_analysis" in results:
            report += "## ğŸ‘ï¸ VLM Analysis Results\n"
            vlm_data = results["vlm_analysis"]
            avg_score = (
                sum(data.get("consistency_score", 0) for data in vlm_data.values())
                / len(vlm_data)
                if vlm_data
                else 0
            )
            report += f"- Analyzed {len(vlm_data)} images\n"
            report += f"- Average consistency score: {avg_score:.3f}\n\n"

        if "monitoring" in results:
            report += "## ğŸ“Š System Performance\n"
            monitoring = results["monitoring"]
            metrics = monitoring.get("metrics", {})
            report += f"- CPU Usage: {metrics.get('cpu_percent', 0):.1f}%\n"
            report += f"- Memory Usage: {metrics.get('memory_percent', 0):.1f}%\n"
            report += f"- Active Workers: {metrics.get('active_workers', 0)}\n\n"

        report += "## ğŸ”§ Recommendations\n\n"

        if failed_tests:
            report += "### Issues Found:\n"
            for test in failed_tests:
                report += f"- {test}: Please check logs for details\n"

        if len(passed_tests) == len(results):
            report += "ğŸ‰ All tests passed! SagaForge is working perfectly.\n"

        report += "\n---\n*Generated by SagaForge Demo Script*"

        return report

    def run_complete_demo(self) -> None:
        """Run the complete SagaForge demonstration workflow"""
        print("ğŸš€ Starting SagaForge Complete Demo")
        print("=" * 50)

        start_time = time.time()
        demo_results = {}

        # Step 1: Health Check
        if not self.check_health():
            print("ğŸ’¥ Demo aborted: API not healthy")
            return

        # Step 2: RAG Pipeline Test
        if self.upload_worldpack():
            demo_results["rag_upload"] = {"success": True}
            demo_results["rag_retrieval"] = self.test_rag_retrieval()
        else:
            demo_results["rag_upload"] = {"success": False}

        # Step 3: LLM Conversation Test
        demo_results["llm_conversation"] = self.test_llm_conversation()

        # Step 4: Image Generation Test
        demo_results["image_generation"] = self.test_image_generation()

        # Step 5: ControlNet Test
        demo_results["controlnet"] = self.test_controlnet_pose()

        # Step 6: VLM Analysis Test
        image_paths = []
        if demo_results["image_generation"]:
            image_paths = [
                data.get("image_path")
                for data in demo_results["image_generation"].values()
            ]
        demo_results["vlm_analysis"] = self.test_vlm_analysis(image_paths)

        # Step 7: Batch Generation Test
        demo_results["batch_generation"] = self.test_batch_generation()

        # Step 8: LoRA Training Test (submission only)
        demo_results["lora_training"] = self.test_lora_training_submission()

        # Step 9: System Monitoring Test
        demo_results["monitoring"] = self.test_monitoring_endpoints()

        # Generate report
        total_time = time.time() - start_time

        print("\n" + "=" * 50)
        print("ğŸ‰ Demo Complete!")
        print("=" * 50)
        print(f"â±ï¸ Total time: {total_time:.1f} seconds")

        # Save report
        report = self.generate_demo_report(demo_results)
        report_path = Path(f"sagaforge_demo_report_{int(time.time())}.md")

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"ğŸ“„ Demo report saved: {report_path}")
        print("\n" + report)


def main():
    """Main demo function"""
    import argparse

    parser = argparse.ArgumentParser(description="SagaForge Complete Workflow Demo")
    parser.add_argument(
        "--api-base",
        default="http://localhost:8000",
        help="API base URL (default: http://localhost:8000)",
    )
    parser.add_argument(
        "--quick",
        action="store_true",
        help="Run quick demo (skip batch and training tests)",
    )

    args = parser.parse_args()

    demo = SagaForgeDemo(api_base=args.api_base)

    if args.quick:
        print("ğŸƒ Running quick demo...")
        # Run essential tests only
        demo.check_health()
        demo.upload_worldpack()
        demo.test_rag_retrieval()
        demo.test_llm_conversation()
        demo.test_image_generation()
    else:
        # Run complete demo
        demo.run_complete_demo()


if __name__ == "__main__":
    main()
