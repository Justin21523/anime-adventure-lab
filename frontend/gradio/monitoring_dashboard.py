# frontend/gradio_app/monitoring_dashboard.py
import gradio as gr
import requests
import json
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, Any, List, Tuple
import os

# API Configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")
API_PREFIX = "/api/v1"


class MonitoringUI:
    """Gradio-based monitoring dashboard"""

    def __init__(self):
        self.api_url = f"{API_BASE_URL}{API_PREFIX}"

    def get_system_metrics(self) -> Tuple[str, str, str]:
        """Get system metrics for display"""
        try:
            response = requests.get(f"{self.api_url}/monitoring/metrics", timeout=5)
            if response.status_code == 200:
                data = response.json()

                # Format system info
                system_info = f"""
                **CPU ä½¿ç”¨ç‡**: {data.get('cpu_percent', 0):.1f}%
                **è¨˜æ†¶é«”ä½¿ç”¨ç‡**: {data.get('memory_percent', 0):.1f}%
                **è¨˜æ†¶é«”ä½¿ç”¨é‡**: {data.get('memory_used_gb', 0):.1f} / {data.get('memory_total_gb', 0):.1f} GB
                **ç£ç¢Ÿä½¿ç”¨ç‡**: {data.get('disk_percent', 0):.1f}%
                """

                # GPU info
                gpu_info = "**GPU ç‹€æ…‹**:\n"
                gpu_metrics = data.get("gpu_metrics", {})
                if gpu_metrics:
                    for gpu_id, metrics in gpu_metrics.items():
                        usage = (metrics["memory_used"] / metrics["memory_total"]) * 100
                        gpu_info += f"- {gpu_id.upper()}: {usage:.1f}% ({metrics['memory_used']:.1f}GB / {metrics['memory_total']:.1f}GB)\n"
                else:
                    gpu_info += "- No GPU available\n"

                # Status summary
                status = (
                    "ğŸŸ¢ ç³»çµ±æ­£å¸¸é‹è¡Œ"
                    if data.get("cpu_percent", 0) < 80
                    and data.get("memory_percent", 0) < 85
                    else "ğŸŸ¡ ç³»çµ±è² è¼‰è¼ƒé«˜"
                )

                return system_info, gpu_info, status
            else:
                return "ç„¡æ³•å–å¾—ç³»çµ±è³‡è¨Š", "ç„¡æ³•å–å¾—GPUè³‡è¨Š", "ğŸ”´ API é€£ç·šå¤±æ•—"

        except Exception as e:
            return f"éŒ¯èª¤: {str(e)}", "ç„¡æ³•å–å¾—GPUè³‡è¨Š", "ğŸ”´ é€£ç·šéŒ¯èª¤"

    def get_task_metrics(self) -> Tuple[str, str]:
        """Get task execution metrics"""
        try:
            response = requests.get(f"{self.api_url}/monitoring/tasks", timeout=5)
            if response.status_code == 200:
                data = response.json()

                task_info = f"""
                **ç¸½ä»»å‹™æ•¸**: {data.get('total_tasks', 0)}
                **å·²å®Œæˆ**: {data.get('completed_tasks', 0)}
                **å¤±æ•—æ•¸**: {data.get('failed_tasks', 0)}
                **ç­‰å¾…ä¸­**: {data.get('pending_tasks', 0)}
                **å¹³å‡åŸ·è¡Œæ™‚é–“**: {data.get('avg_execution_time', 0):.0f}ms
                **æ¯åˆ†é˜ä»»å‹™æ•¸**: {data.get('tasks_per_minute', 0):.1f}
                **éŒ¯èª¤ç‡**: {data.get('error_rate', 0):.1%}
                """

                # Task status visualization
                task_chart = self.create_task_chart(data)

                return task_info, task_chart
            else:
                return "ç„¡æ³•å–å¾—ä»»å‹™è³‡è¨Š", None

        except Exception as e:
            return f"éŒ¯èª¤: {str(e)}", None

    def create_task_chart(self, task_data: Dict[str, Any]) -> go.Figure:
        """Create task status pie chart"""
        labels = ["å·²å®Œæˆ", "å¤±æ•—", "ç­‰å¾…ä¸­"]
        values = [
            task_data.get("completed_tasks", 0),
            task_data.get("failed_tasks", 0),
            task_data.get("pending_tasks", 0),
        ]
        colors = ["#10b981", "#ef4444", "#f59e0b"]

        fig = go.Figure(
            data=[
                go.Pie(
                    labels=labels, values=values, marker=dict(colors=colors), hole=0.4
                )
            ]
        )

        fig.update_layout(
            title="ä»»å‹™åŸ·è¡Œç‹€æ…‹ Task Status",
            showlegend=True,
            height=400,
            font=dict(size=12),
        )

        return fig

    def get_batch_jobs(self, status_filter: str = None) -> str:
        """Get recent batch jobs"""
        try:
            params = {"limit": 20}
            if status_filter and status_filter != "å…¨éƒ¨":
                status_map = {
                    "ç­‰å¾…ä¸­": "PENDING",
                    "è™•ç†ä¸­": "PROCESSING",
                    "å·²å®Œæˆ": "COMPLETED",
                    "å¤±æ•—": "FAILED",
                    "å·²å–æ¶ˆ": "CANCELLED",
                }
                params["status"] = status_map.get(status_filter)

            response = requests.get(
                f"{self.api_url}/batch/list", params=params, timeout=5
            )
            if response.status_code == 200:
                data = response.json()
                jobs = data.get("jobs", [])

                if not jobs:
                    return "æš«ç„¡æ‰¹æ¬¡ä»»å‹™"

                # Format job list
                job_list = []
                for job in jobs:
                    progress = 0
                    if job.get("total_items", 0) > 0:
                        progress = (
                            job.get("processed_items", 0) / job["total_items"]
                        ) * 100

                    status_emoji = {
                        "PENDING": "â³",
                        "PROCESSING": "âš¡",
                        "COMPLETED": "âœ…",
                        "FAILED": "âŒ",
                        "CANCELLED": "â¹ï¸",
                    }.get(job.get("status"), "â“")

                    job_info = f"""
                    {status_emoji} **{job.get('job_id', '')[:8]}** - {job.get('job_type', '')}
                    - ç‹€æ…‹: {job.get('status', '')}
                    - é€²åº¦: {progress:.1f}% ({job.get('processed_items', 0)}/{job.get('total_items', 0)})
                    - å»ºç«‹æ™‚é–“: {job.get('created_at', '')[:19] if job.get('created_at') else ''}
                    """

                    if job.get("error_message"):
                        job_info += f"    - éŒ¯èª¤: {job['error_message'][:100]}..."

                    job_list.append(job_info)

                return "\n".join(job_list)
            else:
                return "ç„¡æ³•å–å¾—æ‰¹æ¬¡ä»»å‹™è³‡è¨Š"

        except Exception as e:
            return f"éŒ¯èª¤: {str(e)}"

    def get_worker_status(self) -> str:
        """Get Celery worker status"""
        try:
            response = requests.get(f"{self.api_url}/monitoring/workers", timeout=5)
            if response.status_code == 200:
                workers = response.json()

                if not workers:
                    return "æš«ç„¡æ´»å‹•çš„å·¥ä½œç¯€é»"

                worker_info = []
                for worker in workers:
                    status_emoji = "ğŸŸ¢" if worker.get("active_tasks", 0) > 0 else "ğŸŸ¡"
                    info = f"""
                    {status_emoji} **{worker.get('name', '')}**
                    - æ´»å‹•ä»»å‹™: {worker.get('active_tasks', 0)}
                    - å·²è™•ç†ä»»å‹™: {worker.get('processed_tasks', 0)}
                    - æœ€å¾Œå¿ƒè·³: {worker.get('last_heartbeat', '')[:19] if worker.get('last_heartbeat') else ''}
                    """
                    worker_info.append(info)

                return "\n".join(worker_info)
            else:
                return "ç„¡æ³•å–å¾—å·¥ä½œç¯€é»è³‡è¨Š"

        except Exception as e:
            return f"éŒ¯èª¤: {str(e)}"

    def submit_test_batch(self, job_type: str, item_count: int) -> str:
        """Submit a test batch job"""
        try:
            # Create test inputs based on job type
            if job_type == "caption":
                inputs = [f"/tmp/test_image_{i}.jpg" for i in range(item_count)]
                config = {"max_length": 50, "num_beams": 3}
            elif job_type == "vqa":
                inputs = [
                    {
                        "image_path": f"/tmp/test_image_{i}.jpg",
                        "question": f"What is in this image {i}?",
                    }
                    for i in range(item_count)
                ]
                config = {"max_length": 100}
            elif job_type == "chat":
                inputs = [
                    [{"role": "user", "content": f"Hello, this is test message {i}"}]
                    for i in range(item_count)
                ]
                config = {"max_length": 200, "temperature": 0.7}
            else:
                return "ä¸æ”¯æ´çš„ä»»å‹™é¡å‹"

            payload = {"job_type": job_type, "inputs": inputs, "config": config}

            response = requests.post(
                f"{self.api_url}/batch/submit", json=payload, timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                return f"âœ… æ¸¬è©¦ä»»å‹™å·²æäº¤\nJob ID: {data.get('job_id', '')}\nTask ID: {data.get('task_id', '')}"
            else:
                return f"âŒ æäº¤å¤±æ•—: {response.text}"

        except Exception as e:
            return f"âŒ éŒ¯èª¤: {str(e)}"

    def create_interface(self):
        """Create Gradio interface"""
        with gr.Blocks(
            title="Multi-Modal Lab ç›£æ§å„€è¡¨æ¿", theme=gr.themes.Soft()
        ) as interface:
            gr.Markdown("# ğŸ–¥ï¸ Multi-Modal Lab ç›£æ§å„€è¡¨æ¿")
            gr.Markdown("å³æ™‚ç›£æ§ç³»çµ±è³‡æºã€ä»»å‹™åŸ·è¡Œç‹€æ…‹å’Œæ‰¹æ¬¡è™•ç†é€²åº¦")

            with gr.Tabs():
                # System Monitoring Tab
                with gr.Tab("ğŸ”§ ç³»çµ±ç›£æ§"):
                    with gr.Row():
                        with gr.Column():
                            system_info = gr.Markdown("è¼‰å…¥ä¸­...")
                            gpu_info = gr.Markdown("è¼‰å…¥ä¸­...")
                        with gr.Column():
                            system_status = gr.Markdown("è¼‰å…¥ä¸­...")
                            refresh_btn = gr.Button("ğŸ”„ é‡æ–°æ•´ç†", variant="primary")

                    refresh_btn.click(
                        fn=self.get_system_metrics,
                        outputs=[system_info, gpu_info, system_status],
                    )

                # Task Monitoring Tab
                with gr.Tab("ğŸ“Š ä»»å‹™ç›£æ§"):
                    with gr.Row():
                        with gr.Column():
                            task_info = gr.Markdown("è¼‰å…¥ä¸­...")
                            task_refresh_btn = gr.Button(
                                "ğŸ”„ é‡æ–°æ•´ç†ä»»å‹™", variant="primary"
                            )
                        with gr.Column():
                            task_chart = gr.Plot(label="ä»»å‹™ç‹€æ…‹åœ–è¡¨")

                    task_refresh_btn.click(
                        fn=self.get_task_metrics, outputs=[task_info, task_chart]
                    )

                # Batch Jobs Tab
                with gr.Tab("ğŸ“‹ æ‰¹æ¬¡ä»»å‹™"):
                    with gr.Row():
                        status_filter = gr.Dropdown(
                            choices=[
                                "å…¨éƒ¨",
                                "ç­‰å¾…ä¸­",
                                "è™•ç†ä¸­",
                                "å·²å®Œæˆ",
                                "å¤±æ•—",
                                "å·²å–æ¶ˆ",
                            ],
                            value="å…¨éƒ¨",
                            label="ç‹€æ…‹ç¯©é¸",
                        )
                        jobs_refresh_btn = gr.Button("ğŸ”„ é‡æ–°æ•´ç†", variant="primary")

                    batch_jobs_display = gr.Markdown("è¼‰å…¥ä¸­...")

                    jobs_refresh_btn.click(
                        fn=self.get_batch_jobs,
                        inputs=[status_filter],
                        outputs=[batch_jobs_display],
                    )

                    status_filter.change(
                        fn=self.get_batch_jobs,
                        inputs=[status_filter],
                        outputs=[batch_jobs_display],
                    )

                # Workers Tab
                with gr.Tab("ğŸ‘· å·¥ä½œç¯€é»"):
                    worker_info = gr.Markdown("è¼‰å…¥ä¸­...")
                    worker_refresh_btn = gr.Button(
                        "ğŸ”„ é‡æ–°æ•´ç†å·¥ä½œç¯€é»", variant="primary"
                    )

                    worker_refresh_btn.click(
                        fn=self.get_worker_status, outputs=[worker_info]
                    )

                # Test Tab
                with gr.Tab("ğŸ§ª æ¸¬è©¦å·¥å…·"):
                    gr.Markdown("### æäº¤æ¸¬è©¦æ‰¹æ¬¡ä»»å‹™")
                    with gr.Row():
                        test_job_type = gr.Dropdown(
                            choices=["caption", "vqa", "chat"],
                            value="caption",
                            label="ä»»å‹™é¡å‹",
                        )
                        test_item_count = gr.Slider(
                            minimum=1, maximum=10, value=3, step=1, label="æ¸¬è©¦é …ç›®æ•¸é‡"
                        )
                        submit_test_btn = gr.Button(
                            "ğŸš€ æäº¤æ¸¬è©¦ä»»å‹™", variant="primary"
                        )

                    test_result = gr.Markdown("")

                    submit_test_btn.click(
                        fn=self.submit_test_batch,
                        inputs=[test_job_type, test_item_count],
                        outputs=[test_result],
                    )

            # Auto-refresh every 30 seconds
            interface.load(
                fn=self.get_system_metrics,
                outputs=[system_info, gpu_info, system_status],
            )

            interface.load(fn=self.get_task_metrics, outputs=[task_info, task_chart])

            interface.load(
                fn=self.get_batch_jobs,
                inputs=[status_filter],
                outputs=[batch_jobs_display],
            )

            interface.load(fn=self.get_worker_status, outputs=[worker_info])

        return interface


def create_monitoring_app():
    """Create and launch monitoring dashboard"""
    ui = MonitoringUI()
    interface = ui.create_interface()

    return interface


if __name__ == "__main__":
    app = create_monitoring_app()
    app.launch(
        server_name="0.0.0.0",
        server_port=7861,  # Different port from main Gradio app
        share=False,
        debug=True,
    )
